{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PhotoFF Documentation","text":"<p>PhotoFF is a high-performance image processing library that uses CUDA to achieve exceptional processing speeds. Designed to maximize performance through efficient GPU memory management.</p>"},{"location":"#basic-example","title":"Basic Example","text":"<pre><code>from photoff.operations.filters import apply_gaussian_blur, apply_corner_radius\nfrom photoff.io import save_image, load_image\nfrom photoff import CudaImage\n\n# Load the image in GPU memory\nsrc_image: CudaImage = load_image(\"./assets/stock.jpg\")\n\n# Apply filters\napply_gaussian_blur(src_image, radius=5.0)\napply_corner_radius(src_image, size=200)\n\n# Save the result\nsave_image(src_image, \"./assets/gaussian_blur_test.png\")\n\n# Free the image from GPU memory\nsrc_image.free()\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Pythonic Interface: Clean, intuitive API designed for both beginners and advanced users</li> <li>Robust Image Manipulation: Comprehensive suite of operations including filters, transforms, and compositing</li> <li>Seamless Integration: Works with common image formats through PIL interoperability</li> <li>CUDA-Accelerated Processing: Harness the power of your GPU for blazing-fast image operations</li> <li>Memory-Efficient Design: Optional advanced memory management for optimized buffer management</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<p>Now that you understand the basics, you can:</p> <ul> <li>Explore the Basic Operations to learn about loading, saving, and manipulating images</li> <li>Dive into the Advanced Operations to discover more complex image processing techniques</li> <li>Check out the API Reference for detailed documentation on all available functions and classes</li> </ul>"},{"location":"advanced/","title":"PhotoFF Advanced Topics","text":"<p>This guide covers advanced techniques for optimizing performance when working with the PhotoFF library, with special focus on efficient GPU memory management through buffer reuse.</p>"},{"location":"advanced/#understanding-gpu-memory-management","title":"Understanding GPU Memory Management","text":""},{"location":"advanced/#the-cost-of-gpu-memory-operations","title":"The Cost of GPU Memory Operations","text":"<p>When working with CUDA-accelerated image processing, memory operations are among the most expensive:</p> <ol> <li>Allocations: Each call to <code>CudaImage()</code> triggers a <code>cudaMalloc()</code> operation which is relatively slow</li> <li>Transfers: Moving data between CPU and GPU memory is extremely expensive</li> </ol> <p>PhotoFF provides several strategies to minimize these costs:</p>"},{"location":"advanced/#strategic-buffer-reuse-patterns","title":"Strategic Buffer Reuse Patterns","text":""},{"location":"advanced/#1-operation-output-caching","title":"1. Operation Output Caching","text":"<p>Many operations naturally produce new output (resize, crop, filters). PhotoFF allows passing pre-allocated destination buffers instead of creating new memory:</p> <pre><code>from photoff.operations.fill import fill_gradient\nfrom photoff.operations.resize import resize, ResizeMethod\nfrom photoff.io import save_image\nfrom photoff import CudaImage, RGBA\n\n# Pre-allocate source and destination buffers once\noriginal = CudaImage(1920, 1080)\nresized_cache = CudaImage(800, 600)\n\n# Fill the original image with a gradient\nfill_gradient(original, RGBA(0, 0, 0, 255), RGBA(255, 255, 255, 255))\n\n# Use pre-allocated buffer as destination\nresize(original, 800, 600, method=ResizeMethod.BICUBIC, resize_image_cache=resized_cache)\n\n# Save the resized image\nsave_image(resized_cache, \"./resized_image.png\")\n</code></pre>"},{"location":"advanced/#2-temporary-buffer-reuse","title":"2. Temporary Buffer Reuse","text":"<p>Some operations like blur, shadow, and stroke require a copy of the original image for internal calculations. You can reuse the same temporary buffer across multiple operations:</p> <pre><code>from photoff.operations.filters import apply_gaussian_blur\nfrom photoff.core.buffer import copy_buffers_same_size\nfrom photoff.io import save_image, load_image\nfrom photoff import CudaImage, RGBA\n\n# Create main image and shared temporary buffer\ntemp_buffer = CudaImage(5000, 5000)  # Example for extra buffer space\n\nimage = load_image(\"./assets/stock.jpg\")\n\ntemp_buffer.height = image.height # Set the same size as the main image\ntemp_buffer.width = image.width # Set the same size as the main image\n\n# Copy the main image to the temporary buffer\ncopy_buffers_same_size(temp_buffer.buffer, image.buffer, image.width, image.height) \n\n# Apply the Gaussian blur to the main image, using the temporary buffer as a cache\napply_gaussian_blur(image, radius=5.0, image_copy_cache=temp_buffer)\n\nsave_image(image, \"./test.png\")\n</code></pre>"},{"location":"advanced/#3-logical-dimension-adjustment-the-core-optimization-technique","title":"3. Logical Dimension Adjustment - The Core Optimization Technique","text":"<p>The most powerful feature in PhotoFF is the ability to allocate a large maximum memory buffer once, and then dynamically change its logical dimensions as needed:</p> <pre><code>from photoff.core.types import CudaImage\nfrom photoff.operations.resize import resize, ResizeMethod\n\n# Allocate ONE large buffer with maximum dimensions you'll ever need\n# This is the key pattern - allocate once, reuse everywhere\nmulti_purpose_buffer = CudaImage(5000, 5000)  # 5000x5000 memory allocated\n\n# Now you can change the logical dimensions at any time\n# IMPORTANT: This only changes metadata, not the actual memory allocation!\n# It simply tells PhotoFF functions how much of the buffer to read/write\nmulti_purpose_buffer.width = 800   # Just updates a property, no memory operation\nmulti_purpose_buffer.height = 600  # Just updates a property, no memory operation\n\n# Now use it as a destination buffer for operations\n# The function will only use the first 800x600 pixels of the allocated memory\nresize(source_image, 800, 600, resize_image_cache=multi_purpose_buffer)\n\n# Later, you can change to different dimensions (still using same memory)\nmulti_purpose_buffer.width = 1200   # Again, just changing metadata\nmulti_purpose_buffer.height = 900   # No memory allocation happens\nresize(another_image, 1200, 900, resize_image_cache=multi_purpose_buffer)\n</code></pre> <p>This technique is the heart of PhotoFF's memory optimization. The width and height properties are just metadata that tell operations how much of the pre-allocated memory to use - they don't trigger any GPU memory operations. This allows you to allocate once at startup and never worry about memory fragmentation again.</p>"},{"location":"advanced/#real-world-example-collage-generator","title":"Real-World Example: Collage Generator","text":"<p>The following example from a production collage generator demonstrates all three reuse patterns:</p> <pre><code>from photoff.core.types import CudaImage, RGBA\nfrom photoff.operations.filters import apply_corner_radius\nfrom photoff.operations.utils import cover_image_in_container\nfrom photoff.operations.resize import resize, ResizeMethod\n\n# Pre-allocate buffers once at module level\nPRINT_WIDTH, PRINT_HEIGHT = 2480, 3500\nPREVIEW_WIDTH, PREVIEW_HEIGHT = 600, 848\n\n# These buffers will be reused for all collages created\nprint_collage_cache = CudaImage(PRINT_WIDTH, PRINT_HEIGHT)\npreview_collage_cache = CudaImage(PREVIEW_WIDTH, PREVIEW_HEIGHT)\n\n# Create oversized buffers that will be logically resized as needed\n# This is critical - we allocate maximum needed size once\ncover_cache = CudaImage(5000, 5000)\ncover_resize_cache = CudaImage(5000, 5000)\n\ndef create_collage(grid_data, corner_radius=50, background_color=RGBA(255, 255, 255, 255)):\n    # Reuse print_collage_cache instead of creating a new buffer\n    fill_color(print_collage_cache, background_color)\n\n    for cell in grid_data.cells:\n        # Calculate cell dimensions\n        width = x1_padded - x0_padded\n        height = y1_padded - y0_padded\n\n        # IMPORTANT: Adjust logical dimensions of oversized buffers\n        # This doesn't trigger any memory allocation as long as\n        # width/height are smaller than the allocated buffer size\n        cover_cache.width = width\n        cover_cache.height = height\n\n        # Calculate resize dimensions for cover fit\n        resize_size = get_cover_resize_dimensions(source_image, width, height)\n\n        # Adjust dimensions of the resize cache buffer\n        cover_resize_cache.width = resize_size[0]\n        cover_resize_cache.height = resize_size[1]\n\n        # Use both cache buffers in the operation\n        cover_image_in_container(\n            source_image,\n            width, height,\n            0, 0,\n            background_color,\n            container_image_cache=cover_cache,  # Reuse container buffer\n            resize_image_cache=cover_resize_cache  # Reuse resize buffer\n        )\n\n        # Apply effects and blend with cached destination\n        apply_corner_radius(cover_cache, corner_radius)\n        blend(print_collage_cache, cover_cache, x_position, y_position)\n\n    # Create preview-sized version using another pre-allocated buffer\n    resize(\n        print_collage_cache, \n        PREVIEW_WIDTH, PREVIEW_HEIGHT, \n        method=ResizeMethod.BICUBIC,\n        resize_image_cache=preview_collage_cache  # Reuse preview buffer\n    )\n\n    # Return the preview image (no memory freed as buffers will be reused)\n    return preview_collage_cache\n</code></pre>"},{"location":"advanced/#buffer-validation-and-error-handling","title":"Buffer Validation and Error Handling","text":"<p>PhotoFF validates buffer dimensions before reusing them:</p> <pre><code># From resize.py\nif resize_image_cache.width != width or resize_image_cache.height != height:\n    raise ValueError(\n        f\"Destination image dimensions must match resize dimensions: {width}x{height}, got {resize_image_cache.width}x{resize_image_cache.height}\"\n    )\n</code></pre> <p>This ensures that reused buffers have appropriate dimensions for the operation.</p>"},{"location":"advanced/#cuda-operation-implementation-details","title":"CUDA Operation Implementation Details","text":"<p>Looking at the CUDA implementation, we can see how operations are designed to work with pre-allocated buffers:</p> <pre><code>// Example from photoff.cu - gaussian blur implementation\nvoid apply_gaussian_blur(uchar4* buffer,          // Destination buffer\n                         const uchar4* copy_buffer,  // Source buffer (original image copy)\n                         uint32_t width,\n                         uint32_t height,\n                         float radius) {\n    // Use CUDA kernel with provided buffers\n    gaussianBlurKernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(copy_buffer, buffer, width, height, radius);\n    cudaDeviceSynchronize();\n}\n</code></pre>"},{"location":"advanced/#advanced-buffer-management-strategies","title":"Advanced Buffer Management Strategies","text":""},{"location":"advanced/#1-buffer-pooling","title":"1. Buffer Pooling","text":"<p>For complex applications, implement a buffer pool:</p> <pre><code>class BufferPool:\n    def __init__(self):\n        self.pools = {}  # Maps (width, height) to list of available buffers\n\n    def get_buffer(self, width, height):\n        key = (width, height)\n        if key in self.pools and self.pools[key]:\n            return self.pools[key].pop()\n        return CudaImage(width, height)\n\n    def release_buffer(self, buffer):\n        key = (buffer.width, buffer.height)\n        if key not in self.pools:\n            self.pools[key] = []\n        self.pools[key].append(buffer)\n\n    def clear(self):\n        for buffers in self.pools.values():\n            for buffer in buffers:\n                buffer.free()\n        self.pools.clear()\n</code></pre>"},{"location":"advanced/#2-use-oversized-buffers-with-dynamic-adjustment","title":"2. Use Oversized Buffers with Dynamic Adjustment","text":"<p>Pre-allocate buffers at maximum expected size, then adjust logical dimensions as needed:</p> <pre><code># Allocate maximum possible size\nmax_buffer = CudaImage(4000, 4000)\n\n# When processing a 800x600 image\nmax_buffer.width = 800\nmax_buffer.height = 600\nprocess_image(max_buffer)\n\n# When processing a 1200x900 image\nmax_buffer.width = 1200\nmax_buffer.height = 900\nprocess_image(max_buffer)\n</code></pre> <p>This approach is extremely efficient for processing multiple images of varying sizes.</p>"},{"location":"advanced/#3-context-managers-for-clean-resource-management","title":"3. Context Managers for Clean Resource Management","text":"<pre><code>from contextlib import contextmanager\n\n@contextmanager\ndef using_buffer_pool(buffer_pool, width, height):\n    buffer = buffer_pool.get_buffer(width, height)\n    try:\n        yield buffer\n    finally:\n        buffer_pool.release_buffer(buffer)\n\n# Usage\nwith using_buffer_pool(pool, 800, 600) as temp:\n    # Use temp buffer\n    pass  # Automatically released back to pool when done\n</code></pre>"},{"location":"advanced/#performance-monitoring","title":"Performance Monitoring","text":"<p>Track memory usage and operation timing:</p> <pre><code>from time import time\n\ndef timed_operation(name, func, *args, **kwargs):\n    start = time()\n    result = func(*args, **kwargs)\n    duration = time() - start\n    print(f\"{name} took {duration:.4f} seconds\")\n    return result\n\n# Usage\nresized = timed_operation(\"Resize operation\", \n                         resize, image, 800, 600, \n                         method=ResizeMethod.BICUBIC)\n</code></pre>"},{"location":"advanced/#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li>Pre-allocate buffers at the start of your application</li> <li>Oversized buffers with logical dimension adjustment are extremely efficient</li> <li>Reuse temporary buffers for operations that need them</li> <li>Batch similar operations to minimize context switching</li> <li>Monitor performance to identify memory bottlenecks</li> <li>Minimize host-device transfers by keeping processing on the GPU</li> <li>Size buffers appropriately for your maximum expected dimensions</li> <li>Have a clear ownership strategy for GPU resources to avoid leaks</li> </ol> <p>By implementing these advanced buffer management techniques, you can achieve exceptional performance with PhotoFF while maintaining clean, maintainable code.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#photoff.core.buffer","title":"<code>photoff.core.buffer</code>","text":""},{"location":"api/#photoff.core.buffer.copy_buffers_same_size","title":"<code>copy_buffers_same_size(dst, src, width, height)</code>","text":"<p>Copies data between two CUDA buffers of the same size.</p> <p>This is useful for in-GPU memory operations like duplicating an image or preparing a temporary working buffer.</p> <p>Parameters:</p> Name Type Description Default <code>dst</code> <code>CudaBuffer</code> <p>Destination buffer on the device.</p> required <code>src</code> <code>CudaBuffer</code> <p>Source buffer on the device.</p> required <code>width</code> <code>int</code> <p>Width of the image.</p> required <code>height</code> <code>int</code> <p>Height of the image.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Example <p>copy_buffers_same_size(tmp_buf, original_buf, 512, 512)</p> Source code in <code>photoff/core/buffer.py</code> <pre><code>def copy_buffers_same_size(dst: \"CudaBuffer\", src: \"CudaBuffer\", width: int, height: int) -&gt; None:\n    \"\"\"\n    Copies data between two CUDA buffers of the same size.\n\n    This is useful for in-GPU memory operations like duplicating an image or\n    preparing a temporary working buffer.\n\n    Args:\n        dst (CudaBuffer): Destination buffer on the device.\n        src (CudaBuffer): Source buffer on the device.\n        width (int): Width of the image.\n        height (int): Height of the image.\n\n    Returns:\n        None\n\n    Example:\n        &gt;&gt;&gt; copy_buffers_same_size(tmp_buf, original_buf, 512, 512)\n    \"\"\"\n\n    _lib.copy_buffers_same_size(dst, src, width, height)\n</code></pre>"},{"location":"api/#photoff.core.buffer.copy_to_device","title":"<code>copy_to_device(d_dst, h_src, width, height)</code>","text":"<p>Copies image data from host (CPU) to device (GPU) memory.</p> <p>Parameters:</p> Name Type Description Default <code>d_dst</code> <code>CudaBuffer</code> <p>Destination buffer in device memory.</p> required <code>h_src</code> <code>CudaBuffer</code> <p>Source buffer in host memory.</p> required <code>width</code> <code>int</code> <p>Width of the image.</p> required <code>height</code> <code>int</code> <p>Height of the image.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Example <p>copy_to_device(gpu_buf, cpu_buf, 256, 256)</p> Source code in <code>photoff/core/buffer.py</code> <pre><code>def copy_to_device(d_dst: \"CudaBuffer\", h_src: \"CudaBuffer\", width: int, height: int) -&gt; None:\n    \"\"\"\n    Copies image data from host (CPU) to device (GPU) memory.\n\n    Args:\n        d_dst (CudaBuffer): Destination buffer in device memory.\n        h_src (CudaBuffer): Source buffer in host memory.\n        width (int): Width of the image.\n        height (int): Height of the image.\n\n    Returns:\n        None\n\n    Example:\n        &gt;&gt;&gt; copy_to_device(gpu_buf, cpu_buf, 256, 256)\n    \"\"\"\n\n    _lib.copy_to_device(d_dst, h_src, width, height)\n</code></pre>"},{"location":"api/#photoff.core.buffer.copy_to_host","title":"<code>copy_to_host(h_dst, d_src, width, height)</code>","text":"<p>Copies image data from device (GPU) to host (CPU) memory.</p> <p>Parameters:</p> Name Type Description Default <code>h_dst</code> <code>CudaBuffer</code> <p>Destination buffer in host memory.</p> required <code>d_src</code> <code>CudaBuffer</code> <p>Source buffer in device memory.</p> required <code>width</code> <code>int</code> <p>Width of the image.</p> required <code>height</code> <code>int</code> <p>Height of the image.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Example <p>copy_to_host(cpu_buf, gpu_buf, 256, 256)</p> Source code in <code>photoff/core/buffer.py</code> <pre><code>def copy_to_host(h_dst: \"CudaBuffer\", d_src: \"CudaBuffer\", width: int, height: int) -&gt; None:\n    \"\"\"\n    Copies image data from device (GPU) to host (CPU) memory.\n\n    Args:\n        h_dst (CudaBuffer): Destination buffer in host memory.\n        d_src (CudaBuffer): Source buffer in device memory.\n        width (int): Width of the image.\n        height (int): Height of the image.\n\n    Returns:\n        None\n\n    Example:\n        &gt;&gt;&gt; copy_to_host(cpu_buf, gpu_buf, 256, 256)\n    \"\"\"\n\n    _lib.copy_to_host(h_dst, d_src, width, height)\n</code></pre>"},{"location":"api/#photoff.core.buffer.create_buffer","title":"<code>create_buffer(width, height)</code>","text":"<p>Allocates a new CUDA buffer for an image of given dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>width</code> <code>int</code> <p>Width of the buffer in pixels.</p> required <code>height</code> <code>int</code> <p>Height of the buffer in pixels.</p> required <p>Returns:</p> Name Type Description <code>CudaBuffer</code> <code>CudaBuffer</code> <p>A pointer to the allocated device memory buffer.</p> Example <p>buffer = create_buffer(512, 512)</p> Source code in <code>photoff/core/buffer.py</code> <pre><code>def create_buffer(width: int, height: int) -&gt; \"CudaBuffer\":\n    \"\"\"\n    Allocates a new CUDA buffer for an image of given dimensions.\n\n    Args:\n        width (int): Width of the buffer in pixels.\n        height (int): Height of the buffer in pixels.\n\n    Returns:\n        CudaBuffer: A pointer to the allocated device memory buffer.\n\n    Example:\n        &gt;&gt;&gt; buffer = create_buffer(512, 512)\n    \"\"\"\n\n    return _lib.create_buffer(width, height)\n</code></pre>"},{"location":"api/#photoff.core.buffer.free_buffer","title":"<code>free_buffer(buffer)</code>","text":"<p>Frees a CUDA buffer previously allocated on the device.</p> <p>Parameters:</p> Name Type Description Default <code>buffer</code> <code>CudaBuffer</code> <p>The buffer to free.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Example <p>free_buffer(buffer)</p> Source code in <code>photoff/core/buffer.py</code> <pre><code>def free_buffer(buffer: \"CudaBuffer\") -&gt; None:\n    \"\"\"\n    Frees a CUDA buffer previously allocated on the device.\n\n    Args:\n        buffer (CudaBuffer): The buffer to free.\n\n    Returns:\n        None\n\n    Example:\n        &gt;&gt;&gt; free_buffer(buffer)\n    \"\"\"\n\n    _lib.free_buffer(buffer)\n</code></pre>"},{"location":"api/#photoff.core.types","title":"<code>photoff.core.types</code>","text":""},{"location":"api/#photoff.core.types.CudaImage","title":"<code>CudaImage</code>","text":"<p>Represents an image stored in GPU memory with optional dimension constraints.</p> <p>The image has an underlying GPU buffer and stores its logical and allocated dimensions. Use <code>.width</code> and <code>.height</code> to manage the actual used size, while the allocation size is fixed on creation. Memory is managed via <code>create_buffer</code> and <code>free_buffer</code>.</p> <p>Attributes:</p> Name Type Description <code>width</code> <code>int</code> <p>Logical width (can be set lower than allocated width).</p> <code>height</code> <code>int</code> <p>Logical height (can be set lower than allocated height).</p> <code>buffer</code> <code>Any</code> <p>Pointer to the underlying CUDA buffer.</p> <p>Methods:</p> Name Description <code>init_image</code> <p>Allocates the GPU buffer if not already allocated.</p> <code>free</code> <p>Frees the associated GPU buffer.</p> Example <p>img = CudaImage(512, 512) img.width = 256  # Use only part of the allocation img.free()</p> Source code in <code>photoff/core/types.py</code> <pre><code>class CudaImage:\n    \"\"\"\n    Represents an image stored in GPU memory with optional dimension constraints.\n\n    The image has an underlying GPU buffer and stores its logical and allocated dimensions.\n    Use `.width` and `.height` to manage the actual used size, while the allocation\n    size is fixed on creation. Memory is managed via `create_buffer` and `free_buffer`.\n\n    Attributes:\n        width (int): Logical width (can be set lower than allocated width).\n        height (int): Logical height (can be set lower than allocated height).\n        buffer (CudaBuffer): Pointer to the underlying CUDA buffer.\n\n    Methods:\n        init_image(): Allocates the GPU buffer if not already allocated.\n        free(): Frees the associated GPU buffer.\n\n    Example:\n        &gt;&gt;&gt; img = CudaImage(512, 512)\n        &gt;&gt;&gt; img.width = 256  # Use only part of the allocation\n        &gt;&gt;&gt; img.free()\n    \"\"\"\n\n    def __init__(self, width: int, height: int, auto_init: bool = True):\n        \"\"\"\n        Initializes a new CudaImage with specified dimensions.\n\n        Args:\n            width (int): Allocation and initial logical width in pixels.\n            height (int): Allocation and initial logical height in pixels.\n            auto_init (bool, optional): Whether to automatically allocate the buffer. Defaults to True.\n        \"\"\"\n\n        self._alloc_width  = width\n        self._alloc_height = height\n\n        self._width  = width\n        self._height = height\n\n        self.buffer = None\n        if auto_init:\n            self.init_image()\n\n    @property\n    def width(self) -&gt; int:\n        return self._width\n\n    @width.setter\n    def width(self, value: int):\n        if value &gt; self._alloc_width:\n            raise ValueError(f\"width {value} &gt; alloc_width {self._alloc_width}\")\n        self._width = value\n\n    @property\n    def height(self) -&gt; int:\n        return self._height\n\n    @height.setter\n    def height(self, value: int):\n        if value &gt; self._alloc_height:\n            raise ValueError(f\"height {value} &gt; alloc_height {self._alloc_height}\")\n        self._height = value\n\n    def init_image(self):\n        if self.buffer is None:\n            self.buffer = create_buffer(self._alloc_width, self._alloc_height)\n\n    def free(self):\n        if self.buffer is not None:\n            free_buffer(self.buffer)\n            self.buffer = None\n</code></pre>"},{"location":"api/#photoff.core.types.CudaImage.__init__","title":"<code>__init__(width, height, auto_init=True)</code>","text":"<p>Initializes a new CudaImage with specified dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>width</code> <code>int</code> <p>Allocation and initial logical width in pixels.</p> required <code>height</code> <code>int</code> <p>Allocation and initial logical height in pixels.</p> required <code>auto_init</code> <code>bool</code> <p>Whether to automatically allocate the buffer. Defaults to True.</p> <code>True</code> Source code in <code>photoff/core/types.py</code> <pre><code>def __init__(self, width: int, height: int, auto_init: bool = True):\n    \"\"\"\n    Initializes a new CudaImage with specified dimensions.\n\n    Args:\n        width (int): Allocation and initial logical width in pixels.\n        height (int): Allocation and initial logical height in pixels.\n        auto_init (bool, optional): Whether to automatically allocate the buffer. Defaults to True.\n    \"\"\"\n\n    self._alloc_width  = width\n    self._alloc_height = height\n\n    self._width  = width\n    self._height = height\n\n    self.buffer = None\n    if auto_init:\n        self.init_image()\n</code></pre>"},{"location":"api/#photoff.core.types.RGBA","title":"<code>RGBA</code>  <code>dataclass</code>","text":"<p>Represents an RGBA color with 8-bit channels.</p> <p>Attributes:</p> Name Type Description <code>r</code> <code>int</code> <p>Red channel (0 \u2013 255).</p> <code>g</code> <code>int</code> <p>Green channel (0 \u2013 255).</p> <code>b</code> <code>int</code> <p>Blue channel (0 \u2013 255).</p> <code>a</code> <code>int</code> <p>Alpha channel (0 \u2013 255), defaults to 255 (opaque).</p> Example <p>color = RGBA(255, 0, 0)  # Opaque red transparent_black = RGBA(0, 0, 0, 0)</p> Source code in <code>photoff/core/types.py</code> <pre><code>@_dataclass\nclass RGBA:\n    \"\"\"\n    Represents an RGBA color with 8-bit channels.\n\n    Attributes:\n        r (int): Red channel (0 \u2013 255).\n        g (int): Green channel (0 \u2013 255).\n        b (int): Blue channel (0 \u2013 255).\n        a (int): Alpha channel (0 \u2013 255), defaults to 255 (opaque).\n\n    Example:\n        &gt;&gt;&gt; color = RGBA(255, 0, 0)  # Opaque red\n        &gt;&gt;&gt; transparent_black = RGBA(0, 0, 0, 0)\n    \"\"\"\n    r: int\n    g: int\n    b: int\n    a: int = 255\n</code></pre>"},{"location":"basics/","title":"PhotoFF Basics","text":"<p>This guide covers the fundamental concepts and operations of the PhotoFF library. After reading this, you'll understand how to load, manipulate, and save images using GPU acceleration.</p>"},{"location":"basics/#core-concepts","title":"Core Concepts","text":""},{"location":"basics/#cudaimage","title":"CudaImage","text":"<p>The <code>CudaImage</code> class is the central object in PhotoFF. It represents an image stored in GPU memory as a RGBA buffer.</p> <p>Note: <code>CudaImage</code> does not guarantee that the newly reserved GPU memory is zero\u2011initialized. If you plan to use the image as a fully transparent background, clear it right after allocation:</p> <pre><code>from photoff.core.types import CudaImage, RGBA\nfrom photoff.operations.fill import fill_color\n\nimage = CudaImage(800, 600)\nfill_color(image, RGBA(0, 0, 0, 0))  # Ensure full transparency\n</code></pre> <pre><code>from photoff.core.types import CudaImage\n\n# Reserving GPU memory for an 800x600 image\nimage = CudaImage(800, 600)\n\n# Free the image from GPU memory when done\nimage.free()\n</code></pre>"},{"location":"basics/#rgba","title":"RGBA","text":"<p>PhotoFF uses the RGBA color model (Red, Green, Blue, Alpha) for all operations:</p> <pre><code>from photoff.core.types import RGBA\n\n# Create colors\nred = RGBA(255, 0, 0, 255)         # Solid red\nblue = RGBA(0, 0, 255, 255)        # Solid blue\nsemi_transparent = RGBA(0, 255, 0, 128)  # Semi-transparent green\ntransparent = RGBA(0, 0, 0, 0)     # Completely transparent\n</code></pre>"},{"location":"basics/#basic-operations","title":"Basic Operations","text":""},{"location":"basics/#loading-and-saving-images","title":"Loading and Saving Images","text":"<p>To load images from disk and save them back:</p> <pre><code>from photoff.io import load_image, save_image\nfrom photoff.core.types import CudaImage\n\n# Load an image from disk into GPU memory\nimage = load_image(\"input.jpg\")\n\n# Save an image to disk\nsave_image(image, \"output.png\")\n\n# Free the image from GPU memory\nimage.free()\n</code></pre>"},{"location":"basics/#image-filling","title":"Image Filling","text":"<p>Fill an image with a solid color or gradient:</p> <pre><code>from photoff.operations.fill import fill_color, fill_gradient\nfrom photoff.core.types import CudaImage, RGBA\n\n# Create and fill with solid color\nimage = CudaImage(400, 300)\nfill_color(image, RGBA(255, 0, 0, 255))  # Fill with red\n\n# Fill with gradient\nstart_color = RGBA(255, 0, 0, 255)  # Red\nend_color = RGBA(0, 0, 255, 255)    # Blue\ndirection = 0  # 0: horizontal, 1: vertical, 2: diagonal, 3: radial\nseamless = False\nfill_gradient(image, start_color, end_color, direction, seamless)\n\n# Free the image from GPU memory\nimage.free()\n</code></pre>"},{"location":"basics/#applying-filters","title":"Applying Filters","text":"<p>PhotoFF offers various filters to modify images:</p> <pre><code>from photoff.operations.filters import apply_gaussian_blur, apply_corner_radius, apply_grayscale\nfrom photoff.io import load_image, save_image\n\n# Load an image\nimage = load_image(\"input.jpg\")\n\n# Apply a Gaussian blur\napply_gaussian_blur(image, radius=5.0)\n\n# Round the corners\napply_corner_radius(image, size=20)\n\n# Convert to grayscale\napply_grayscale(image)\n\n# Save the result\nsave_image(image, \"filtered.png\")\n\n# Free the image from GPU memory\nimage.free()\n</code></pre>"},{"location":"basics/#resizing-images","title":"Resizing Images","text":"<p>Resize images with different interpolation methods:</p> <pre><code>from photoff.operations.resize import resize, ResizeMethod\nfrom photoff.io import load_image, save_image\n\n# Load an image\nimage = load_image(\"input.jpg\")\n\n# Resize to 400x300 using bicubic interpolation\nresized = resize(image, 400, 300, method=ResizeMethod.BICUBIC)\n\n# Save the result\nsave_image(resized, \"resized.png\")\n\n# Free both images\nimage.free()\nresized.free()\n</code></pre>"},{"location":"basics/#blending-images","title":"Blending Images","text":"<p>Combine multiple images together:</p> <pre><code>from photoff.operations.blend import blend\nfrom photoff.io import load_image, save_image\nfrom photoff.core.types import CudaImage, RGBA\nfrom photoff.operations.fill import fill_color\n\n# Create a background\nbackground = CudaImage(800, 600)\nfill_color(background, RGBA(200, 200, 200, 255))  # Light gray\n\n# Load a foreground image\nforeground = load_image(\"logo.png\")\n\n# Blend the foreground onto the background at position (100, 100)\nblend(background, foreground, 100, 100)\n\n# Save the result\nsave_image(background, \"blended.png\")\n\n# Free the images from GPU memory\nbackground.free()\nforeground.free()\n</code></pre>"},{"location":"basics/#next-steps","title":"Next Steps","text":"<p>Now that you understand the basics, you can:</p> <ul> <li>Explore the Advanced Topics for more memory management and performance tips</li> <li>Check the API Reference for detailed information on all functions</li> </ul>"},{"location":"installation/","title":"PhotoFF Installation Guide (Linux &amp; Windows)","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing PhotoFF, ensure you have the following prerequisites:</p> <ul> <li>Python 3.9 or newer</li> <li>NVIDIA GPU with CUDA support</li> <li>CUDA Toolkit 11.0 or newer \u2013 Required for compiling the CUDA components</li> <li>CFFI \u2013 Used for interfacing between Python and the CUDA library</li> <li>Pillow \u2013 Used for image loading, saving, and text rendering</li> <li>NumPy \u2013 Used for memory management when transferring image data to/from CUDA</li> </ul>"},{"location":"installation/#python-dependencies","title":"Python Dependencies","text":"<p>Install the required Python packages:</p> <pre><code>pip install cffi pillow numpy\n</code></pre>"},{"location":"installation/#installing-cuda-toolkit","title":"Installing CUDA Toolkit","text":"<ol> <li>Download the CUDA Toolkit from the NVIDIA Developer website</li> <li>Follow the instructions for your OS (Linux or Windows)</li> <li>Ensure <code>nvcc</code> is accessible:    <pre><code>nvcc --version\n</code></pre></li> </ol>"},{"location":"installation/#compiling-the-cuda-library","title":"Compiling the CUDA Library","text":""},{"location":"installation/#for-linux","title":"\ud83d\udc27 For Linux:","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/offerrall/photoff.git\ncd photoff\n</code></pre></p> </li> <li> <p>Compile the <code>.so</code> shared object:    <pre><code>python3 photoff_cuda_src/compile_linux.py\n</code></pre></p> </li> <li> <p>You\u2019ll get <code>photoff.so</code>.</p> </li> <li> <p>Make it available system-wide:</p> </li> </ol> <p>Option A: Temporary <pre><code>export LD_LIBRARY_PATH=/your/path/photoff:$LD_LIBRARY_PATH\n</code></pre></p> <p>Option B: Permanent    Add to <code>~/.bashrc</code> or <code>~/.zshrc</code>:    <pre><code>export LD_LIBRARY_PATH=/your/path/photoff:$LD_LIBRARY_PATH\nsource ~/.bashrc\n</code></pre></p> <p>Option C: System-wide <pre><code>echo \"/your/path/photoff\" | sudo tee /etc/ld.so.conf.d/photoff.conf\nsudo ldconfig\n</code></pre></p>"},{"location":"installation/#for-windows","title":"\ud83e\ude9f For Windows:","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/offerrall/photoff.git\ncd photoff\n</code></pre></p> </li> <li> <p>Compile the <code>.dll</code> using:    <pre><code>python photoff_cuda_src/compile_windows.py\n</code></pre></p> </li> <li> <p>Add the folder containing <code>photoff.dll</code> to your system PATH:</p> </li> <li>Search for \u201cEnvironment Variables\u201d in the Start menu</li> <li>Edit the PATH variable, and add the folder path</li> <li>Restart your terminal or IDE</li> </ol>"},{"location":"installation/#installing-the-python-package","title":"Installing the Python Package","text":"<p>Run this in the root of the project (after compilation):</p> <pre><code>pip install .\n</code></pre>"},{"location":"installation/#verifying-the-installation","title":"Verifying the Installation","text":"<p>Test your installation with the following Python script:</p> <pre><code>from photoff.operations.fill import fill_color\nfrom photoff.io import save_image\nfrom photoff.core.types import CudaImage, RGBA\n\n# Create a 200x200 red square\nimg = CudaImage(200, 200)\nfill_color(img, RGBA(255, 0, 0, 255))\nsave_image(img, \"red_square.png\")\nimg.free()\n\nprint(\"Installation successful!\")\n</code></pre> <p>If you see the image <code>red_square.png</code> and the message \u201cInstallation successful!\u201d, your setup is working.</p>"},{"location":"installation/#notes","title":"Notes","text":"<ul> <li>CFFI will load the appropriate file based on your OS</li> </ul>"},{"location":"installation/#license","title":"License","text":"<p>PhotoFF is distributed under the MIT license.</p>"}]}